---
title: "Predicci√≥n del voto electoral en Espa√±a"
title-slide-attributes:
  data-background-image: img/data-science-2.jpeg
  data-background-size: cover
  data-background-opacity: "0.2"
author: "Javier √Ålvarez Li√©bana y Enric Palau Payeras (UCM) ‚Ä¢ SEIO 2023 (Elche)"
affiliation: Facultad de Estudios Estad√≠sticos (UCM)
lang: es
language: custom_lang.yml
format: 
  revealjs:
    theme: [default, style.scss]
    chalkboard: true
    multiplex: true
    menu:
      side: left
      width: normal
    footer: "[<strong>Javier √Ålvarez Li√©bana</strong>](...) ‚Ä¢ SEIO 2023 (Elche) ‚Ä¢ Fac. Estad√≠stica (UCM)"
    slide-number: c/t
execute:
  echo: true
---

# Contexto, objetivos y antecedentes

[**Incertidumbre electoral**]{style="color:#444442;"}

---

## Contexto

-   El clima pol√≠tico espa√±ol lleva experimentando grandes cambios sistem√°ticos desde 2008, pasando de un [**sistema pr√°cticamente bipartidista**]{.hl-yellow} a un sistema donde prima la [**estrategia de pactos**]{.hl-yellow} multipartidista.

. . .

::: columns
::: {.column width="65%"}
-   En √©pocas de crisis, como la pandemia de COVID-19 o las repeticiones electorales de 2019, la [**expectaci√≥n por los resultados electorales**]{.hl-yellow} es m√°xima.
:::

::: {.column width="35%"}
![](img/quien-ganara.jpg)
:::
:::

. . .

-   Sin embargo, a pesar de contar con cada vez [**m√°s casas demosc√≥picas**]{.hl-yellow} y agregadores (¬´food chain feeding demand¬ª), se ha extendido la idea de que las [**encuestas electorales no funcionan**]{.hl-yellow} y que no sirven para predecir el voto.

---

## Objetivos

::: callout-tip
## Objetivo 1: estudiar errores sistem√°ticos

Automatizar un [**proceso de extracci√≥n, transformaci√≥n y carga del hist√≥rico de datos electorales**]{.hl-yellow} as√≠ como de las proyecci√≥n demosc√≥picas de las casas encuestadoras en Espa√±a a nivel nacional.

:::

. . .

::: callout-tip
## Objetivo 2: analizar sesgos sistem√°ticos (house effects)

Analizar la [**desviaci√≥n sistem√°tica de las casas encuestadoras**]{.hl-yellow}, [^1] desagregado por casa encuestadora, partido, bloque ideol√≥gico y cita electoral, entre otras variables.

:::

. . .

::: callout-tip
## Objetivo 3: predecir con Machine Learning

Se aplicar√°n distintos [**algoritmos predictivos de Machine Learning**]{.hl-yellow} para mejorar tanto las predicciones de las casas encuestadoras como los promedios de agregadores electorales (Kiko Llaneras, TheElectoralReport [^2], etc)

:::

[^1]: Masters, A.B.(2020). Estimating House Effects. <https://medium.com/swlh/estimating-houseeffects-5c465f2aca87>

[^2]:  <https://app.precisaresearch.com/>


---

## Antecedentes

* Pocos son los/as autores/as que han aplicado [**t√©cnicas de Machine Learning**]{.hl-yellow} [^1a] para la predicci√≥n de resultados electorales (al menos cuya metodolog√≠a sea p√∫blica y transparente).

. . .

* En la mayor√≠a de casos dichas predicciones son hechas por medios de comunicaci√≥n, institutos demosc√≥picos, partidos electorales o [**agregadores**]{.hl-yellow} (TheElectoralReport o FiveThirtyEight [^2a] [^3a]). 


[^1a]: Hare, C., and Kutsuris, M. (2022). Measuring Swing Voters with a Supervised Machine Learning Ensemble. Political Analysis 31.

[^2a]: Silver, N. (2012). Calculating ‚ÄòHouse Effects‚Äô of Polling Firms. <https://fivethirtyeight.com/features/calculatinghouse-effects-of-polling-firms>

[^3a]: Silver, N. (2020). How FiveThirtyEight‚Äôs 2020 Presidential Forecast Works ‚Äî And What‚Äôs Different Because Of COVID-19. <https://fivethirtyeight.com/features/how-fivethirtyeights-2020presidential-forecast-works-and-whats-different-because-of-covid-19/>


---


## Antecedentes


* Recientemente ha llegado a Espa√±a los conocidos como [**mercados de predicci√≥n**]{.hl-yellow} [^4a]: una especie de mercado de apuestas en los que se predice la intenci√≥n de voto en funci√≥n del consenso de los apostantes.

. . .

* Algunos autores proponen algunas [**alternativas a las encuestas**]{.hl-yellow} para proporcionar a los partidos una estimaci√≥n de su intenci√≥n de voto basado en el [**an√°lisis de reputaci√≥n**]{.hl-yellow}  de sus candidatos [^1aa], como predictores correlados de dicha intenci√≥n de voto.


[^4a]: Ortega, A.L. (2022). ¬øC√≥mo funciona el mercado de predicci√≥n? <https://aloport.github.io/predi/projects.html>

[^1aa]: Guti√©rrez-Rodr√≠guez, P., Villareal, R., Cuesta-Vali√±o, P., Blozis, S. A. (2023). Valuation of candidate brand equity dimensions and voting intention: alternative polling data in the Spanish presidential election. Humanities and Social Sciences Communications 10,



---

## Antecedentes

* Tambi√©n se han usado recientemente el m√©todo [**Network scale-up (Network scale-up method, NSUM)**]{.hl-yellow}  [^1b] [^2b] para la estimaci√≥n de intenci√≥n de voto, haciendo uso de [**preguntas indirectas**]{.hl-yellow}  para la estimaci√≥n del tama√±o de una subpoblaci√≥n de votantes [^3b]

[^1b]: Maltiel, R., Raftery, A.E., McCormick, T.H., Baraff, A.J. (2015). Estimating Population Size Using the Network Scale Up Method. Ann Appl Stat 9

[^2b]: Kunke, J.P., Laga, I., Niu, X., McCormick, T.H. (2023). Comparing the Robustness of Simple Network Scale-Up Method (NSUM) Estimators. Center for statistics and the social science.

[^3b]: Mart√≠n-Arevalillo, J., Ram√≠rez, J.M., D√≠az-Aranda, S., Aguilar, J., Fern√°ndez-Anta, A., Lillo, R.E. (2023). Study and estimation of voting intention by network scale up methods. SEIO 2023.


# Software empleado y fuentes de datos

---

## Software empleado

* Para la recolecci√≥n y depuraci√≥n de los datos hemos usado tanto [**R**]{.hl-yellow} como [**SQL**]{.hl-yellow}.

* Para el an√°lisis exploratorio, visualizaci√≥n y modelizaci√≥n hemos usado R

* Todo el c√≥digo se encuentra libremente disponible en [**Github**]{.hl-yellow} en  <https://github.com/3nriket/TFM_encuestas_y_elecciones_EPP_UCM_2023>

![](img/Rlogo.png){width=400}
![](img/Sql_data_base_with_logo.png){width=400}

---

## Fuentes de datos

Se han usado fundamentalmente [**3 tipos de bases de datos**]{.hl-yellow}

* [**Proyecciones demosc√≥picas**]{.hl-yellow}. Se automatizar√° la recopilaci√≥n de [**datos agregados**]{.hl-purple} de encuestas a nivel nacional.

. . .

* [**Resultados electorales**]{.hl-yellow}. Se extraer√°n [**datos electorales**]{.hl-purple} (censo, porcentaje de voto, etc) provenientes del Ministerio del Interior.

. . .

* [**Variables externas socioecon√≥micas**]{.hl-yellow}. Se extraer√°n [**variables socioecon√≥micas**]{.hl-purple} provenientes del INE, CIS, etc

. . .

> La idea principal del trabajo es que una encuesta, en un instante temporal, falla, pero la evoluci√≥n del conjunto de las mismas nos puede servir para realizar predicciones certeras.


# Metodolog√≠a: extracci√≥n y depuraci√≥n

## Variable objetivo

[**¬øCu√°l es la variable objetivo?**]{.hl-yellow}

. . .

* Denotaremos como $\hat{V}_{ij}(t)$ la [**predicci√≥n de porcentaje de voto**]{.hl-yellow} de una casa encuestadora $s_i$, para un partido $p_j$, en un instante temporal $t$ previo a las elecciones.

. . .

* Denotaremos como $V_{j}$ el [**porcentaje de voto real**]{.hl-yellow} obtenido el d√≠a de las elecciones.

. . .

Por cada casa encuestadora $s_i$ y partido $p_j$, en un instante temporal $t$, anterior a las elecciones, tenemos entonces que

$$V_{j} = \hat{V}_{ij}(t) + \varepsilon_{ij}(t), \quad i=1,\ldots,E, \quad j=1,\ldots, P$$

---

## Variable objetivo

$$V_{j} = \hat{V}_{ij}(t) + \varepsilon_{ij}(t), \quad i=1,\ldots,E, \quad j=1,\ldots, P$$

En contraste con uno de los paradigmas principales del Machine Learning, en nuestro problema de [**medidas repetidas**]{.hl-yellow}, con un mismo valor de la variable objetivo $V_j$ para una muestra de predictoras  $V_{j} = \hat{V}_{ij}(t)$

. . .


&nbsp;


El [**objetivo de este trabajo**]{.hl-yellow} es ser capaces de, en un instante de tiempo $t$ estimar los errores cometidos por cada encuestadora $\hat{\varepsilon}_{ij}(t)$, para cada partido, de manera que la [**estimaci√≥n agregada final**]{.hl-yellow} sea el resultado del promedio de sus predicciones, tras corregirlas por los errores estimados cometidos

$$\hat{V}_{j} = \frac{1}{E} \sum_{i=1}^{E} \left( \hat{V}_{ij}(t) + \hat{\varepsilon}_{ij}(t) \right), \quad j=1,\ldots, P$$

---

## Depuraci√≥n: encuestas

Los [**datos agregados de las encuestadoras**]{.hl-yellow} proceden de bases de datos abiertas como la Wikipedia

![](img/encuestas-wiki.jpg)

El objetivo ser√° predecir el porcentaje de voto real (primera fila de la tabla), por los principales partidos pol√≠ticos (rect√°ngulo discontinuo azul), en las distintas carreras electorales desde 1982 hasta la actualidad, haciendo uso de la estimaci√≥n de voto de cada casa (matriz de valores del recuadro verde).

---

## Depuraci√≥n: encuestas



La [**automatizaci√≥n en la extracci√≥n**]{.hl-yellow} cont√≥ con los siguientes pasos:

* Generaci√≥n de una [**base de datos de links**]{.hl-yellow} en los que realizar la b√∫squeda de resultados mediante el uso con expresiones regulares para las distintas elecciones desde 1982.


* Acceso al c√≥digo html para extraer de los [**png de los logos los nombres**]{.hl-yellow} de los partidos pol√≠ticos


![](img/wiki-links.jpg){width=700}

---

## Depuraci√≥n: encuestas

Una vez construida la base de (meta)datos, se [**accedi√≥ al c√≥digo html**]{.hl-yellow} de cada una de ellas para extraer los datos de cada una de las tablas. Estos son algunos de los pasos adoptados en la depuraci√≥n

. . .

* [**Recodificar**]{.hl-green} el nombre de los partidos y casas encuestadoras.

. . .

* C√°lcular el n√∫mero de [**d√≠as de trabajo de campo**]{.hl-green} de cada encuesta y los [**d√≠as que quedan**]{.hl-green} para la celebraci√≥n de las elecciones.

. . .

* [**Descartar encuestas sin tama√±o muestral**]{.hl-red} o con [**menos de 1 d√≠a de trabajo de campo**]{.hl-red}, as√≠ como encuestas realizadas por partidos.

. . .


* Dado que el primer objetivo ser√° [**rankear el binomio casa encuestadora - partido**]{.hl-yellow}, se procedi√≥ a [**descartar casas poco frecuentes**]{.hl-red} (<1%) cuya precisi√≥n no podemos calibrar.

---

## Depuraci√≥n: encuestas

La [**tabla (tidy data) resultante se aproxima a las 12 000 observaciones**]{.hl-yellow} (porcentaje de voto que una encuestadora estima, para cada partido, fecha de campo y carrera electoral), identificando de manera un√≠voca cada encuesta (casa encuestadora + fechas de campo)

![](img/encuestas-preproc.jpg)

---

## Depuraci√≥n: elecciones

Los [**datos relativos a resultados electorales**]{.hl-yellow} se han obtenido a trav√©s del portal Infoelectoral del Ministerio del Interior, a trav√©s del proyecto de paquete de R `{pollspain}`, que tenemos actualmente en desarrollo.

&nbsp;


En esta fuente, los datos se encuentran desagregados por [**distritos electorales**]{.hl-yellow}, que para esta tentativa preliminar hemos decidido [**agregarlos a nivel nacional**]{.hl-yellow}, para cada partido y carrera electorales, tanto el porcentaje de voto como variables que cuantifique el censo, la participaci√≥n, votos blancos y votos nulos.

&nbsp;

Se ha tenido que realizar un arduo trabajo de normalizaci√≥n de los partidos

---

## Depuraci√≥n: elecciones


Con los datos de casas encuestadores y los resultados reales, podremos construir tanto el [**promedio/consenso de mercado**]{.hl-yellow} (encuestas ponderadas por su tama√±o muestral y ventana temporal) como el an√°lisis de las [**desviaciones respecto a la realidad**]{.hl-yellow}

![](img/electoral-results.jpg)

---


## Depuraci√≥n: ex√≥genas

[**¬øPor qu√© incluir variables ex√≥genas?**]{.hl-yellow}

. . .

Aunque considerar en modelos de predicci√≥n electoral solo variables ex√≥genas puede incorporar excesivo ruido y tener un bajo poder predictivo, no incorporarlas puede ocasionar un [**incremento del sesgo y variabilidad del error al modelo, especialmente si las encuestadoras han fallado**]{.hl-yellow} o no han sido correctamente seleccionadas

&nbsp;

Nate Silver [^1c] cuantific√≥ en un 30% la variabilidad explicada por las condiciones econ√≥micas en las elecciones americanas de 2020.

[^1c]: Silver, N. (2020). How FiveThirtyEight‚Äôs 2020 Presidential Forecast Works ‚Äî And What‚Äôs Different Because Of COVID-19. Fivethirtyeight. <https://fivethirtyeight.com/features/how-fivethirtyeights-2020presidential-forecast-works-and-whats-different-because-of-covid-19/>

---

## Depuraci√≥n: ex√≥genas

Por ello hemos [**recopilado variables ex√≥genas desde 1980**]{.hl-yellow}, agrupadas en los siguientes bloques tem√°ticos:

* [**Medio ambiente**]{.hl-purple}: generaci√≥n y consumo el√©ctrico, emisiones de CO2, reservas de petr√≥leo, etc. Seg√∫n las encuestas de IPSOS ¬´en Espa√±a, del 74% al 88% de los potenciales electores estar√≠a considerando votar a un partido que reduzca la factura energ√©tica e impulse la transici√≥n energ√©tica¬ª [^1e]


. . .

* [**Demograf√≠a y sociedad**]{.hl-purple}: esperanza de vida, casos de violencia machista, etc.  De acuerdo con el informe de IPSOS [^1e], la justicia social es una preocupaci√≥n emergente entre los votantes en Espa√±a.

[^1e]: Encuesta IPSOS para Grupo Crecimiento Verde (2019). El medio ambiente pesa en la decisi√≥n de voto <https://grupocrecimientoverde.org/elmedio-ambiente-pesa-en-la-decision-de-voto/>

---


## Depuraci√≥n: ex√≥genas

Por ello hemos [**recopilado variables ex√≥genas desde 1980**]{.hl-yellow}, agrupadas en los siguientes bloques tem√°ticos:

* [**Econom√≠a**]{.hl-purple}: inflaci√≥n, IPC, etc. Dicha inclusi√≥n est√° basada en los postulados de Fearon (1998), Kuklinski y West (1981) y Lewis-Beck y Skalaban (1989), como se ilustra en Jaime-Castillo et al. (2014) [^saez], que indicaban que el voto econ√≥mico es un instrumento para seleccionar al que el individuo considera el mejor de los candidatos de la carrera (aunque no por una mayor√≠a de ciudadanos).

[^saez]: Jaime-Castillo, A.M., S√°ez-Lozano, J.L.(2014). Atribuci√≥n de la responsabilidad y voto econ√≥mico El caso de Espa√±a. El trimestre econ√≥mico 81. <https://www.eltrimestreeconomico.com.mx/index.php/te/article/view/369/70>

. . .
  
* [**Pol√≠tica y Gobierno**]{.hl-purple}: gesti√≥n del gobierno, presupuestos generales del estado, etc. 

. . .

En este trabajo hemos incorporado finalmente **31 indicadores a nivel nacional**. 


# Metodolog√≠a: an√°lisis de errores

---

## House effects

La [**hip√≥tesis principal**]{.hl-yellow} del trabajo no es (de momento) desarrollar el mejor m√©todo de predicci√≥n en el contexto de Machine Learning, sino ilustrar como, con m√©todos ya conocidos, se puede obtener un [**buen resultado predictivo entendiendo los sesgos sistem√°ticos de las casas encuestadoras**]{.hl-yellow}.


&nbsp;

. . .

El [**simple promedio ponderado**]{.hl-yellow} de encuestas de los medios de comunicaci√≥n y agregadores solo nos ofrece una [**fotograf√≠a del estado de la precisi√≥n**]{.hl-yellow} de las casas encuestadoras, pero no permite ofrecer precisi√≥n a partir de cierto umbral

. . .

&nbsp;

El objetivo del trabajo es chequear como con t√©cnicas de Machine Learning, el [**consenso de los errores**]{.hl-yellow} puede ayudarnos a una predicci√≥n precisa.

---

## House effects


Sea $\hat{V}_{ij}(t)$ la predicci√≥n de intenci√≥n de voto de cada casa encuestadora $s_i$ y para cada partido $p_j$, en un instante temporal $t$, y sea $\varepsilon_{ij}(t)$ el error real que est√°n cometiendo (cuando $t$ es la cita electoral) y $V_{j}$ el resultado real para cada partido, tal que 

$$\varepsilon_{ij}(t) = V_{j} - \hat{V}_{ij}(t) , \quad i=1,\ldots,E, \quad j=1,\ldots, P$$


. . .

Llamaremos [**house effect**]{.hl-yellow}, denotado como $HE_{ij}$ al [**sesgo sistem√°tico**]{.hl-yellow} (a lo largo del tiempo $[t_0, t_1]$) de una casa encuestadora [**respecto al promedio**]{.hl-yellow} de un partido o bloque ideol√≥gico, definido como


$$HE_{ij}(t_0, t_1) = \frac{1}{\left| T \right|}\sum_{t \in T} \left| \hat{V}_{ij}(t) - \frac{1}{\left| T \right|}\sum_{t \in T} \omega_{i,j} \hat{V}_{ij}(t)\right|$$


---

## House effects y promedios

Para analizar dichas desviaciones se han definido diferentes [**promedios**]{.hl-yellow}, todos ellos [**ponderados por tama√±o de la encuesta y ventana temporal**]{.hl-yellow} (encuestas con mayor muestra y m√°s recientes tendr√°n m√°s peso)

* [**Promedio general partido**]{.hl-purple}: promedio ponderado de todas las estimaciones de voto, de todas las casas, para un determinado partido, en un rango temporal.

. . .

* [**Promedio general ideol√≥gico**]{.hl-purple}: promedio ponderado de todas las estimaciones de voto, de todas las casas, para un determinado bloque ideol√≥gico, en un rango temporal.

. . .

* [**Promedio casa partido**]{.hl-purple}: promedio ponderado de todas las estimaciones de voto, para un determinado partido y casa encuestadora.

. . .

* [**Promedio casa ideol√≥gico**]{.hl-purple}: promedio ponderado de todas las estimaciones de voto,  para un determinado bloque ideol√≥gico y casa encuestadora.

---

## House effects y promedios


As√≠ el [**house effect**]{.hl-yellow} puede ser definido como la [**infraestimaci√≥n o sobreestimaci√≥n**]{.hl-yellow} de una casa encuestadora respecto a un partido/bloque [**respecto al promedio ponderado**]{.hl-yello2} correspondiente, para un periodo de tiempo dado para cada cita electoral.

. . .

:::: columns
::: {.column width="35%"}

[**Ejemplo**]{.hl-green}: para las √∫ltimas elecciones de 2019 se refleja un sesgo sistem√°tico favorable al PP y/o ala derecha de encuestadoras como Gesop. Por otro lado, el CIS tuvo un sesgo sistem√°tico en favor de PSOE y al ala izquierda. 


:::

::: {.column width="65%"}

![](img/house-effect-casas.jpg)
:::
::::

---

## House effects y promedios


![Los puntos de colores son las estimaciones de cada encuesta; los puntos con contorno negro representan el promedio de la casa; la barra representa el promedio de mercado; y la l√≠nea horizontal equivale al voto observado.](img/house-effect-partido-casa.jpg)


Estos sesgos no solo no los consideramos perjudiciales para nuestros modelos sino que, si son continuados en el tiempo, la hip√≥tesis es que servir√°n a nuestros modelos como un "recuerdo de estimaci√≥n".



# Metodolog√≠a: t√©cnicas Machine Learning


---

## Train-validaci√≥n-test

En el trabajo se excluyeron las recientes elecciones de 2023. De las 11 036 restantes se decidi√≥ [**particionar**]{.hl-yellow} como sigue

* [**Entrenamiento (train)**]{.hl-yellow}: 80% de los datos
  - **Validaci√≥n**: validaci√≥n cruzada con $k = 4$ folds y 100 repeticiones.

* [**Test**]{.hl-yellow}: 20% de los datos

. . .

La [**m√©trica o bondad de ajuste**]{.hl-yellow} a evaluar ser√° el [**error medio absoluto (MAE)**]{.hl-yello2} (m√°s adecuado para modelos que tengan bajo error de predicci√≥n pero con valores extremos e inestables en los errores)

---

## Competidores

[**Referencia**]{.hl-yellow}: por tener una referencia, el error absoluto medio de los promedios de encuestas en Espa√±a ronda los [**dos puntos por partido**]{.hl-yellow}

![](img/mae-theelectoralreport.jpg)

---

## Missing y outliers

Aunque algunos modelos son robustos frente a outliers y ausentes, con el objetivo de ganar interpretabilidad y armon√≠a entre los modelos construido, se decidido [**imputar**]{.hl-yellow} estos datos. Para ello se compar√≥ dos metodolog√≠as:

:::: columns
::: {.column width="25%"}


* Imputaci√≥n por [**estad√≠sticos de localizaci√≥n**]{.hl-yellow}

* Imputaci√≥n por [**bagging**]{.hl-yellow}



:::

::: {.column width="75%"}

![](img/distribucion.jpg)

:::

::::


El **MAE conseguido en los modelos con variables imputadas por estad√≠sticos es ligeramente peor** que el de los modelos con imputaci√≥n por Bagging, siendo respectivamente de 1.2 y 0.9.

---

## Modelos de predicci√≥n

* [**√Årboles**]{.hl-yellow}: usaremos √°rboles de regresi√≥n para predecir nuestro error continuo.
  - **M√©todo de divisi√≥n**: usamos F de Snedecor (ANOVA), que toma la divisi√≥n que varie m√°s la media de la variable dependiente.
  - **cp**: par√°metro de poda
  - **minbucket**: n√∫mero de observaciones m√≠nimas en cada nodo final (desde un 1% (70) hasta un 20%).
  - **maxsurrogate**: el √°rbol no usa todas las variables, va seleccionando las mejores (m√©todo de selecci√≥n _embedded_).

----

## Modelos de predicci√≥n

![](img/mejor-arbol.jpg)

---

## Modelos de predicci√≥n


![](img/arbol-comparativa.jpg)

---

## Modelos de predicci√≥n

c a fin de superar las limitaciones de los √°rboles, usaremos modelos con el mismo concepto base y con el m√©todo de Ensamblado (combinando m√∫ltiples modelos en uno nuevo).  En el caso del Baggin se han seleccionado $n<N$ observaciones con reemplazamiento (o sin) de los datos originales y se aplica un √°rbol.

&nbsp;

* [**Random Forest**]{.hl-yellow}: incorporar la aleatoriedad en las variables utilizadas para segmentar cada nodo del √°rbol. El proceso es pr√°cticamente igual, pero a diferencia del que se hace en Bagging, cada vez que se abre un nodo seleccionaremos $p$ ($p = 129$) variables de las $k$ originales y de esas $p$ elegidas se escoge la mejor para llevar a cabo la partici√≥n en ese nodo.

---

## Modelos de predicci√≥n


![](img/rf-mejor.jpg)


---

## Modelos de predicci√≥n


![](img/rf-comparativa.jpg)

---

## Modelos de predicci√≥n

* [**Gradient Boosting**]{.hl-yellow}: formados por un conjunto de √°rboles de decisi√≥n, entrenados de forma secuencial, de forma que cada nuevo √°rbol trata de mejorar los errores de los √°rboles anteriores, modificando las predicciones en la direcci√≥n de decrecimiento dada por el negativo del gradiente de la funci√≥n de error (con _Early Stopping_ para evitar el sobreajuste y marcar as√≠ un n√∫mero de iteraciones de parada).
  - **Shrinkage ($Œª$) o ‚Äúlearning rate‚Äù**: representa el ritmo de aprendizaje y cuanto menor sea, m√°s interaciones se necesitan. En nuestro caso var√≠a desde 0.001 (valor por defecto) hasta 1. 


---

## Modelos de predicci√≥n

![](img/gbm-mejor.jpg)

---

## Modelos de predicci√≥n

![](img/gbm-comparativa.jpg)

---

## Modelos de predicci√≥n

* [**Redes Neuronales**]{.hl-yellow}: a fin de complementar los inconvenientes de los filtros o rankear variables, aqu√≠ se recurri√≥ a _wrappers_ como t√©cnica de selecci√≥n de variables (m√©todos de b√∫squeda secuencial que bucean entre distintas combinaciones de variables)

&nbsp;

* [**Modelos SVM**]{.hl-yellow} con kernels lineales y polinomiales de grado 2 y 3.

---

## Modelos de predicci√≥n


![](img/svm-mejor.jpg)

---

## Modelos de predicci√≥n

![](img/svm-comparativa.jpg)

---

## Modelos de predicci√≥n


![](img/final.jpg)

# Conclusiones y l√≠neas abiertas

[**¬øQu√© hemos conseguido? ¬øQu√© nos falta?**]{style="color:#444442;"}

---

## Conclusiones

- Se ha creado una [**automatizaci√≥n para la recopilaci√≥n**]{.hl-yellow} tanto de encuestas como de datos electorales en nuestro pa√≠s.

. . .

- Se ha comprobado que el hecho de que las casas encuestadoras cometan [**sesgos sistem√°ticos**]{.hl-yellow} puede ser incluso beneficioso en la predicci√≥n, alimentando a los modelos con diferentes de variables que les permita capturar algo similar a un ¬´recuerdo de estimaci√≥n¬ª.

. . .

-   Se ha desarrollado una metodolog√≠a propia (y a√∫n as√≠ preliminar) para predecir la intenci√≥n de voto, alcanzando en el mejor de los casos un error medio absoluto (MAE) de 0.21, frente a la mejor casa encuestadora (GAD3 con un MAE de 1.9) o al promedio de ellas (2.2 de MAE)

. . .

-  Vimos que los datos de encuestas y promedios son los bloques de variables que m√°s informaci√≥n aportan y los m√°s seleccionados entre nuestros modelos.


---

## L√≠neas abiertas futuras

::: columns
::: {.column width="60%"}
üü• [**Debilidad**]{.hl-red}: dificultad para la predicci√≥n de [**partidos nuevos**]{.hl-red} sin informaci√≥n sobre el sesgo de las encuestas
:::

::: {.column width="40%"}
![](img/logos-partidos.jpeg)
:::
:::

. . .

‚úÖ [**Futura soluci√≥n**]{.hl-green}: mejorar en la creaci√≥n de predictoras que permitan a los modelos captar un [**¬´recuerdo de voto¬ª**]{.hl-green}: de partidos nuevos por bloques y regiones, as√≠ como crear modelos para [**estimar matrices de transferencia de voto**]{.hl-green}

---

## L√≠neas abiertas futuras

::: columns
::: {.column width="60%"}
üü• [**Debilidad**]{.hl-red}: todav√≠a [**no incluye variables sociol√≥gicas**]{.hl-red}.
:::

::: {.column width="40%"}
![](img/Logotipo_del_CIS.png)
:::
:::

. . .

‚úÖ [**Futura soluci√≥n**]{.hl-green}: incorporar a los modelos variables sociol√≥gicas extra√≠das de los [**microdatos del CIS**]{.hl-green} (como preocupaciones de los espa√±oles)

---

## L√≠neas abiertas futuras

üü• [**Debilidad**]{.hl-red}: solo considera [**datos agregados**]{.hl-red} de encuestas.

. . .

‚úÖ [**Futura soluci√≥n**]{.hl-green}: automatizar la recopilaci√≥n de [**encuestas a nivel auton√≥mico**]{.hl-green} para posteriormente agregarlas en un modelo nacional

---

## L√≠neas abiertas futuras

::: columns
::: {.column width="60%"}
üü• [**Debilidad**]{.hl-red}: ganar en voto no implicar [**ganar en poder**]{.hl-red}
:::

::: {.column width="40%"}
![](img/escan%CC%83os.jpeg)
:::
:::

. . .

‚úÖ [**Futura soluci√≥n**]{.hl-green}: desarrollar modelos de [**simulaci√≥n de asignaci√≥n de esca√±os**]{.hl-green} (en funci√≥n de cada sistema electoral) en funci√≥n de los datos desagregados por comunidades.

. . .

[**Otras ideas**]{.hl-yellow}: extenderlo a otros sistemas electorales, incluir dependencia entre regiones, etc. Todo ello est√° siendo estudiado para su posterior implementaci√≥n en un [**paquete de R**]{.hl-yellow}, en colaboraci√≥n con la secci√≥n de datos de RTVE.

# ¬°Gracias!

¬†

‚úâÔ∏è [**Mail**]{.hl-yellow}: [javalv09\@ucm.es](mailto:javalv09@ucm.es){.email} (Facultad de Estad√≠stica de la UCM)


&nbsp;

[**Agradecimientos**]{.hl-purple}: ¬´Din√°mica compleja e inferencia no par√°metrica¬ª, proyecto subvencionado por la Agencia Estatal de Investigaci√≥n (AEI) del Ministerio de Ciencia e Innovaci√≥n (PID2020-116587GB-I00)


&nbsp;

&nbsp;

&nbsp;

<p style="text-align: right; font-size:17px;">Diapositivas creadas integramente con **Quarto** en RStudio</p>
